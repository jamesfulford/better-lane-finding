{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "- [x] Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "- [x] Apply a distortion correction to raw images.\n",
    "- [x] Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "- [x] Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "- [ ] Detect lane pixels and fit to find the lane boundary.\n",
    "- [ ] Determine the curvature of the lane and vehicle position with respect to center.\n",
    "- [ ] Warp the detected lane boundaries back onto the original image.\n",
    "- [ ] Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# builtins\n",
    "from glob import glob\n",
    "import functools\n",
    "import os\n",
    "\n",
    "# third-party\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# project-specific\n",
    "from src.calibrate import calibrate\n",
    "from src.thresholding import region_of_interest, thresh, and_binary, or_binary\n",
    "from src.image_mappings import direction, magnitude\n",
    "from src.perspective import get_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finding all calibration images...\")\n",
    "calibration_image_paths = sorted(glob('./camera_cal/calibration*.jpg'), key=lambda p: (len(p), p))\n",
    "calibration_images = list(map(cv2.imread, calibration_image_paths))\n",
    "for path, image in zip(calibration_image_paths, calibration_images):\n",
    "    print(\"{0} ({1[0]}w, {1[1]}h)\".format(\n",
    "        os.path.basename(path),\n",
    "        image.shape\n",
    "    ))\n",
    "print(\"Found {} images.\".format(len(calibration_images)))\n",
    "\n",
    "print(\"Calibrating...\")\n",
    "used_calibration_images, object_points, all_corners, undistort, mtx, dist = calibrate(\n",
    "    calibration_images, \n",
    "    chessboard_dimensions=(9, 6), \n",
    "    to_grayscale_flag=cv2.COLOR_BGR2GRAY\n",
    ")\n",
    "print(\"Calibrated using {} chessboard images (was unable to use {} images).\".format(\n",
    "    len(used_calibration_images), len(calibration_images) - len(used_calibration_images)\n",
    "))\n",
    "\n",
    "print(\"Writing to output_images/chessboards...\")\n",
    "directory = \"output_images/chessboards\"\n",
    "try:\n",
    "    os.mkdir(directory)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for image, corners, i in zip(used_calibration_images, all_corners, range(len(used_calibration_images))):\n",
    "    img = cv2.drawChessboardCorners(image, (9, 6), corners, True)\n",
    "    cv2.imwrite(directory + \"/{}.before.jpg\".format(i), cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "    out = undistort(img)\n",
    "    cv2.imwrite(directory + \"/{}.after.jpg\".format(i), cv2.cvtColor(out, cv2.COLOR_RGB2BGR))\n",
    "    if i == 0:\n",
    "        plt.imshow(out)\n",
    "\n",
    "print(\"Written. Sample output with corners drawn:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_birds_eye, to_car_perspective = get_transformers(np.float32([\n",
    "    [600, 450],\n",
    "    [683, 450],\n",
    "    [1060, 690],\n",
    "    [253, 690],\n",
    "]), np.float32([\n",
    "    [350, 0],\n",
    "    [950, 0],\n",
    "    [950, 720],\n",
    "    [350, 720],\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Defining image selectors...\")\n",
    "# Yes. Lots of fiddling with numbers happened here. Please, never again.\n",
    "\n",
    "def asphalt_selector(img, convert_to_hls_flag=cv2.COLOR_BGR2HLS, convert_to_gray_flag=cv2.COLOR_BGR2GRAY):\n",
    "    hls = cv2.cvtColor(img, convert_to_hls_flag)\n",
    "    gray = cv2.cvtColor(img, convert_to_gray_flag)\n",
    "    return and_binary(\n",
    "        thresh(direction(\n",
    "            thresh(\n",
    "                hls[:,:,1], \n",
    "                (140, 240)\n",
    "            ), \n",
    "            sobel_kernel=5\n",
    "        ), (0.7, 1.8)),\n",
    "        # &\n",
    "        thresh(magnitude(\n",
    "            gray,\n",
    "            sobel_kernel=13\n",
    "        ), (100, 256)),\n",
    "    )\n",
    "\n",
    "def concrete_selector(img, convert_to_hls_flag=cv2.COLOR_BGR2HLS):\n",
    "    hls = cv2.cvtColor(img, convert_to_hls_flag)\n",
    "    return thresh(magnitude(\n",
    "            thresh(hls[:,:,2], (200, 256)),\n",
    "            sobel_kernel=13,\n",
    "        ), (110, 256),\n",
    "    )\n",
    "\n",
    "def region_selector(i):\n",
    "    return region_of_interest(\n",
    "        i, \n",
    "        np.array([[\n",
    "            ((i.shape[1] * 1) / 16, i.shape[0]),\n",
    "            ((i.shape[1] * 7) / 16, i.shape[0] * .61),\n",
    "            ((i.shape[1] * 9) / 16, i.shape[0] * .61),\n",
    "            ((i.shape[1] * 15) / 16, i.shape[0])\n",
    "        ]], dtype=np.int32),\n",
    "    )\n",
    "\n",
    "\n",
    "def lane_selector(img, convert_to_hls_flag=cv2.COLOR_BGR2HLS, convert_to_gray_flag=cv2.COLOR_BGR2GRAY):\n",
    "    return region_selector(\n",
    "        or_binary(\n",
    "            asphalt_selector(img, convert_to_hls_flag=convert_to_hls_flag, convert_to_gray_flag=convert_to_gray_flag),\n",
    "            concrete_selector(img, convert_to_hls_flag=convert_to_hls_flag),\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(\"Defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Showing samples using the selectors...\")\n",
    "img = cv2.imread(\"test_images/test1.jpg\")\n",
    "perp = to_birds_eye(img)\n",
    "hls = cv2.cvtColor(perp, cv2.COLOR_BGR2HLS)\n",
    "\n",
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(to_birds_eye(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)))\n",
    "ax2.imshow(to_birds_eye(asphalt_selector(img)), cmap=\"gray\")\n",
    "ax3.imshow(to_birds_eye(concrete_selector(img)), cmap=\"gray\")\n",
    "ax4.imshow(to_birds_eye(region_selector(lane_selector(img))), cmap=\"gray\")\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Lane Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Defining lane pixel detectors...\")\n",
    "\n",
    "def get_lane_start(img):\n",
    "    histogram = np.sum(img[img.shape[0]//2:,:], axis=0)\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    return (leftx_base, rightx_base)\n",
    "\n",
    "def get_lane_pixels(img, nwindows=9, margin=100, minpix=50):\n",
    "    window_height = np.int(img.shape[0] // nwindows)\n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # to debug:\n",
    "    # out_img = np.dstack((img, img, img))\n",
    "\n",
    "    lane_inds = [\n",
    "        [],  # left lane\n",
    "        [],  # right lane\n",
    "    ]\n",
    "    current = list(get_lane_start(img))  # leftx_current, rightx_current\n",
    "\n",
    "    for window in range(nwindows):\n",
    "        window_boundaries = list(\n",
    "            map(lambda b: (b - margin, b + margin), current)\n",
    "        )\n",
    "        win_y_low = img.shape[0] - (window + 1) * window_height\n",
    "        win_y_high = img.shape[0] - window * window_height\n",
    "        \n",
    "        for i, bound in enumerate(window_boundaries):\n",
    "            leftx, rightx = bound\n",
    "            \n",
    "            # to debug:\n",
    "            # cv2.rectangle(out_img, (leftx, win_y_low), (rightx, win_y_high), (0, 255, 0), 2) \n",
    "\n",
    "            good_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= leftx) &  (nonzerox < rightx)).nonzero()[0]\n",
    "            \n",
    "            lane_inds[i].append(good_inds)\n",
    "            \n",
    "            if len(good_inds) > minpix:\n",
    "                current[i] = np.int(np.mean(nonzerox[good_inds]))\n",
    "\n",
    "    # to debug:\n",
    "    # plt.imshow(out_img)\n",
    "    lane_inds = list(map(np.concatenate, lane_inds))\n",
    "    return [(nonzerox[inds], nonzeroy[inds]) for inds in lane_inds ]\n",
    "\n",
    "\n",
    "def fit_polynomials(img):\n",
    "    ploty = np.linspace(0, img.shape[0] - 1, img.shape[0])    \n",
    "    lane_pixels = get_lane_pixels(img)\n",
    "    quads = list(map(\n",
    "        lambda vp: np.polyfit(vp[1], vp[0], 2),\n",
    "        lane_pixels,\n",
    "    ))\n",
    "    return list(map(\n",
    "        lambda fit: fit[0] * (ploty ** 2)\n",
    "            + fit[1] * (ploty ** 1)\n",
    "            + fit[2], \n",
    "        quads,\n",
    "    ))\n",
    "\n",
    "print(\"Done.\")\n",
    "\n",
    "img = to_birds_eye(lane_selector(cv2.imread(\"test_images/test1.jpg\")))\n",
    "left_fit, right_fit = fit_polynomials(img)\n",
    "ploty = np.linspace(0, img.shape[0] - 1, img.shape[0])\n",
    "plt.plot(left_fit, ploty, color='yellow')\n",
    "plt.plot(right_fit, ploty, color='yellow')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing sample images...\")\n",
    "\n",
    "for image_name in sorted(glob(\"test_images/*.jpg\"), key=lambda p: (len(p), p)):\n",
    "    img = cv2.imread(image_name)\n",
    "    directory = \"output_images/\" + os.path.basename(image_name)\n",
    "    try:\n",
    "        os.mkdir(directory)\n",
    "    except:\n",
    "        pass\n",
    "    print(directory)\n",
    "\n",
    "    cv2.imwrite(directory + \"/original.jpg\", img)\n",
    "    \n",
    "    # Undistort image (virtue of camera lens)\n",
    "    undis = undistort(img)\n",
    "    cv2.imwrite(directory + \"/undistorted.jpg\", undis)\n",
    "    \n",
    "    # Select lanes\n",
    "    asphalt = to_birds_eye(asphalt_selector(undis))  # for show\n",
    "    plt.imsave(directory + \"/asphalt_selector.jpg\", asphalt, cmap='gray')\n",
    "    concrete = to_birds_eye(concrete_selector(undis))  # for show\n",
    "    plt.imsave(directory + \"/concrete_selector.jpg\", concrete, cmap='gray')\n",
    "\n",
    "    lanes = to_birds_eye(lane_selector(undis))\n",
    "    plt.imsave(directory + \"/lane_selector.jpg\", lanes, cmap='gray')\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
